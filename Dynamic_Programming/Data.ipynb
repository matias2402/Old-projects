{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and AR for dynamic programming exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import patsy                           # provides a syntax for specifying models  \n",
    "import statsmodels.api as sm           # provides statistical models like ols, gmm, anova, etc...\n",
    "import statsmodels.formula.api as smf  # provides a way to directly spec models from formulas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "file_directory = os.getcwd() + '\\\\Data\\\\' + 'sparadata.xls' \n",
    "data = pd.read_excel(file_directory, skipfooter = 3) # Remove last 3 rows that are NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data set for structural estimaiton. We remove observations where individuals retired before the age of 60\n",
    "data_structural = data.copy()\n",
    "data_structural[\"invalid\"] = ((data_structural[\"ret\"] == 1) & (data_structural[\"age\"] < 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs to filter out\n",
    "filter_cond = data_structural[(data_structural['invalid'] == True).groupby(data_structural['id']).transform('any')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(filter_cond.columns.values)\n",
    "i1 = data_structural.set_index(keys).index\n",
    "i2 = filter_cond.set_index(keys).index\n",
    "data_structural = data_structural[~i1.isin(i2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data compatible with the solution of the model with all 5 state variables\n",
    "data_structural[\"ret_age\"] = data_structural[\"id\"].map(data_structural[data_structural[\"ret\"] == 1].set_index(\"id\")[\"age\"])\n",
    "data_structural = data_structural.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step regression for income \n",
    "data['income_lead'] = data.groupby([\"id\"])[\"income\"].shift(-1) # Create new column with wage tomorrow for each person\n",
    "data = data.dropna() # Drop last row for each person with no observaiton for tomorrow's wage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data for the reduced form AR(1) model - ignore error data is correct \n",
    "data[\"log_income\"] = np.log(data[\"income\"])\n",
    "data[\"log_income_lead\"] = np.log(data[\"income_lead\"])\n",
    "data[\"age_squared\"] = data[\"age\"] * data[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        log_income_lead   R-squared:                       0.809\n",
      "Model:                            OLS   Adj. R-squared:                  0.809\n",
      "Method:                 Least Squares   F-statistic:                 6.590e+04\n",
      "Date:                Thu, 02 Jun 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:48:10   Log-Likelihood:                 18133.\n",
      "No. Observations:               46734   AIC:                        -3.626e+04\n",
      "Df Residuals:                   46730   BIC:                        -3.622e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.2376      0.153      1.551      0.121      -0.063       0.538\n",
      "log_income      0.8868      0.002    444.529      0.000       0.883       0.891\n",
      "age             0.0133      0.005      2.451      0.014       0.003       0.024\n",
      "age_squared    -0.0001   4.81e-05     -2.627      0.009      -0.000   -3.21e-05\n",
      "==============================================================================\n",
      "Omnibus:                    29340.802   Durbin-Watson:                   2.390\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         17022273.337\n",
      "Skew:                          -1.701   Prob(JB):                         0.00\n",
      "Kurtosis:                      96.435   Cond. No.                     6.37e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.37e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Income first step regression \n",
    "model = smf.ols('log_income_lead ~ log_income + age + age_squared', data = data)\n",
    "\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026949281380785624"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance of the error term \n",
    "results.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step regression for ATP points \n",
    "\n",
    "# Load data again because we removed last row for each person before when we did the regression for income \n",
    "data = pd.read_excel(file_directory, skipfooter = 3) # Remove last 3 rows that are NA \n",
    "\n",
    "data['atp_lead'] = data.groupby([\"id\"])[\"atp\"].shift(-1) # Create new column with next period ATP points \n",
    "data.drop(data[data.atp == 0].index, inplace = True) # Drop rows with ATP points = 0. We will take the log later\n",
    "data = data.dropna() # Drop last row for each person with no observaiton for tomorrow's ATP points  \n",
    "\n",
    "# Transform data for the regression\n",
    "data[\"log_atp\"] = np.log(data[\"atp\"])\n",
    "data[\"log_atp_lead\"] = np.log(data[\"atp_lead\"])\n",
    "data[\"age_squared\"] = data[\"age\"] * data[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           log_atp_lead   R-squared:                       0.997\n",
      "Model:                            OLS   Adj. R-squared:                  0.997\n",
      "Method:                 Least Squares   F-statistic:                 4.701e+06\n",
      "Date:                Thu, 02 Jun 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:48:11   Log-Likelihood:             1.0493e+05\n",
      "No. Observations:               46733   AIC:                        -2.099e+05\n",
      "Df Residuals:                   46729   BIC:                        -2.098e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -0.0428      0.024     -1.791      0.073      -0.090       0.004\n",
      "log_atp         0.9733      0.000   3751.206      0.000       0.973       0.974\n",
      "age             0.0040      0.001      4.680      0.000       0.002       0.006\n",
      "age_squared -4.162e-05    7.5e-06     -5.547      0.000   -5.63e-05   -2.69e-05\n",
      "==============================================================================\n",
      "Omnibus:                   104028.578   Durbin-Watson:                   1.031\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       2971182157.734\n",
      "Skew:                          20.091   Prob(JB):                         0.00\n",
      "Kurtosis:                    1237.606   Cond. No.                     6.36e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.36e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# ATP points first step regression \n",
    "model_atp = smf.ols('log_atp_lead ~ log_atp + age + age_squared', data = data)\n",
    "\n",
    "results_atp = model_atp.fit()\n",
    "print(results_atp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006565512692947586"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance of the error term \n",
    "results_atp.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition probabilities for marital status \n",
    "\n",
    "# Load data again to get the last row we removed before in the first step regression\n",
    "file_directory = os.getcwd() + '\\\\Data\\\\' + 'sparadata.xls' \n",
    "data = pd.read_excel(file_directory, skipfooter = 3) # Remove last 3 rows that are NA \n",
    "\n",
    "# Create two data sets\n",
    "data_m = data.copy()\n",
    "data_u = data.copy()\n",
    "\n",
    "# Probability of married today and divorced tomorrow (and probability of married today and married tomorrow)\n",
    "data_m[\"married_next\"] = data_m.groupby([\"id\"])[\"married\"].shift(-1)\n",
    "data_m.dropna(inplace = True)\n",
    "\n",
    "# = 1 if married today and divorced tomorrow, = 0 if not married today or tomorrow, = - 1 if not married today but married \n",
    "# tomorrow, = 0 if married today and tomorrow. We want only married today + tomorrow and married today + divorced tomorrow\n",
    "data_m[\"m-unm\"] = data_m[\"married\"] - data_m[\"married_next\"]\n",
    "\n",
    "# = 2 if married today and married tomorrow, = 1 if married today and divorced tomorrow, = 1 if unmarried today but married\n",
    "# tomorrow, = 0 if not married today or tomorrow. \n",
    "data_m[\"um-um\"] = data_m[\"married\"] + data_m[\"married_next\"]\n",
    "\n",
    "# Drop relevant rows so that column \"m-unm\" is = 1 if ONLY married today + divorced tomorrow and = 0 if ONLY married today\n",
    "# + married tomorrow \n",
    "data_m.drop(data_m[data_m[\"m-unm\"] == -1].index, inplace = True)\n",
    "data_m.drop(data_m[data_m[\"um-um\"] == 0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of being married today and divorced tomorrow is 1.26%\n",
      "The probability of being married today and married tomorrow is 98.74%\n"
     ]
    }
   ],
   "source": [
    "# Compute probability of being married today and divorced tomorrow \n",
    "married_to_unmarried = data_m[\"m-unm\"].sum()\n",
    "observations = data_m.shape[0]\n",
    "\n",
    "married_to_unmarried_prob = married_to_unmarried / observations * 100 \n",
    "married_to_married_prob = 100 - married_to_unmarried_prob\n",
    "\n",
    "print(\"The probability of being married today and divorced tomorrow is {:1.2f}%\".format(married_to_unmarried_prob))\n",
    "print(\"The probability of being married today and married tomorrow is {:1.2f}%\".format(married_to_married_prob))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition probabilities for marital status #2\n",
    "\n",
    "# Probability of unmarried today and married tomorrow (and unmarried today and unmarried tomorrow)\n",
    "data_u[\"married_next\"] = data_u.groupby([\"id\"])[\"married\"].shift(-1)\n",
    "data_u.dropna(inplace = True)\n",
    "\n",
    "# = 2 if married today and tomorrow, = 1 if married today and divorced tomorrow, = 1 if unmarried today and married tomorrow\n",
    "# = 0 if unmarried today and unmarried tomorrow. We want only unmarried today + married tomorrow and unmarried today + \n",
    "# unmarried tomorrow. \n",
    "data_u[\"unm-m\"] = data_u[\"married\"] + data_u[\"married_next\"] \n",
    "\n",
    "# = -1 if married today and divorced tomorrow\n",
    "data_u[\"m-unm\"] = data_u[\"married_next\"] - data_u[\"married\"]\n",
    "\n",
    "# Drop relevant rows so that column \"unm-m\" is either = 0 or 1 and = 1 if ONLY unmarried today and married tomorrow\n",
    "data_u.drop(data_u[data_u[\"unm-m\"] == 2].index, inplace = True) \n",
    "data_u.drop(data_u[data_u[\"m-unm\"] == -1].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of being unmarried today and married tomorrow is 1.36%\n",
      "The probability of being unmarried today and unmarried tomorrow is 98.64%\n"
     ]
    }
   ],
   "source": [
    "# Compute probability of being unmarried today and married tomorrow \n",
    "\n",
    "unmarried_to_married = data_u[\"unm-m\"].sum()\n",
    "observations_unmarried_to_married = data_u.shape[0]\n",
    "\n",
    "unmarried_to_married_prob = unmarried_to_married / observations_unmarried_to_married * 100\n",
    "unmarried_to_unmarried_prob = 100 - unmarried_to_married_prob\n",
    "\n",
    "print(\"The probability of being unmarried today and married tomorrow is {:1.2f}%\".format(unmarried_to_married_prob))\n",
    "print(\"The probability of being unmarried today and unmarried tomorrow is {:1.2f}%\".format(unmarried_to_unmarried_prob))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Data cleaning \n",
    "file_directory = os.getcwd() + '\\\\Data\\\\' + 'surv.xls' \n",
    "data_surv = pd.read_excel(file_directory, skipfooter = 7, skiprows = range(1,21), header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "58    0.995535\n",
       "59    0.986674\n",
       "60    0.955882\n",
       "61    0.930644\n",
       "62    0.899113\n",
       "63    0.855077\n",
       "64    0.694113\n",
       "65    0.224149\n",
       "66    0.171301\n",
       "67    0.140372\n",
       "68    0.112297\n",
       "69    0.102939\n",
       "70    0.102939\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCP for sample (Hazard rates)\n",
    "data[\"work\"] = 1 - data.ret # = 1 if working, = 0 if retired\n",
    "working = data.groupby([\"age\"])[\"work\"].sum()\n",
    "retiring = data.groupby([\"age\"])[\"ret\"].sum()\n",
    "hazard_rates = retiring / (working + retiring)\n",
    "CCP_sample = np.ones(np.shape(hazard_rates)) - hazard_rates\n",
    "CCP_sample = CCP_sample[8:] # get correct age\n",
    "np.cumprod(CCP_sample) # Share of population working at given age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "50    0.000000\n",
       "51    0.000560\n",
       "52    0.000264\n",
       "53    0.001254\n",
       "54    0.001194\n",
       "55    0.000908\n",
       "56    0.002381\n",
       "57    0.004557\n",
       "58    0.004465\n",
       "59    0.008900\n",
       "60    0.031208\n",
       "61    0.026403\n",
       "62    0.033881\n",
       "63    0.048977\n",
       "64    0.188245\n",
       "65    0.677071\n",
       "66    0.235772\n",
       "67    0.180556\n",
       "68    0.200000\n",
       "69    0.083333\n",
       "70    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hazard_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.39865657449695"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected retirement age (weighted average)\n",
    "sum(np.arange(50,71) * np.transpose(hazard_rates)) / hazard_rates.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
